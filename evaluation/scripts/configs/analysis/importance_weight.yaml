# Model arguments
model_name_or_path: WizardLM/WizardLM-70B-V1.0
torch_dtype: bfloat16
use_flash_attention_2: true

# Data training arguments
# all train_ splits will be mixed, subsampled, and used for training,
# and all test_ splits will be mixed and used for evaluation
# to make sure all dsets have the same 'formatting', see src/dataloads/formatting.py
dataset_splits:
  # HuggingFaceH4/ultrafeedback_binarized: ["test_prefs"]
  # when2rl/distilabel-intel-orca-dpo-pairs_cleaned_reformatted: ["train"]
  when2rl/UltraFeedback_binarized_cleaned_annotated: ['train_prefs', 'test_prefs']
  # when2rl/distilabel-capybara-dpo-7k-binarized_reformatted: ['train']
  # when2rl/dpo-mix-7k-rescaled_reformatted: ['train', 'test']
dataset_mixer:
  # HuggingFaceH4/ultrafeedback_binarized: 1.0
  # when2rl/distilabel-intel-orca-dpo-pairs_cleaned_reformatted: 1.0
  when2rl/UltraFeedback_binarized_cleaned_annotated: 1.0
  # when2rl/distilabel-capybara-dpo-7k-binarized_reformatted: 1.0
  # when2rl/dpo-mix-7k-rescaled_reformatted: 1.0
preprocessing_num_workers: 12

# DPOTrainer arguments. Note that we are not doing any training
bf16: true
beta: 0.01
do_eval: true
do_train: false
log_level: info
logging_steps: 10
max_length: 1024
max_prompt_length: 512
optim: adamw_torch
output_dir: data/analysis/orca_pairs/WizardLM-70B-V1.0_weights
per_device_eval_batch_size: 4
per_device_train_batch_size: 2  # we inference on training set
push_to_hub: false
report_to:
- none
save_strategy: "no"
seed: 42